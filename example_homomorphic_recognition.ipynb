{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ab00f1c",
      "metadata": {
        "id": "9ab00f1c"
      },
      "source": [
        "# Homomorphic Facial Recognition with TenSEAL\n",
        "\n",
        "This notebook demonstrates how to perform facial recognition while preserving privacy using Homomorphic Encryption (HE). The key privacy benefit is that we can perform facial comparison operations on encrypted data without ever having access to the actual facial embeddings.\n",
        "\n",
        "## How Homomorphic Encryption Protects Privacy\n",
        "\n",
        "1. **Traditional Approach (Privacy Risk)**:\n",
        "   - Facial embeddings are sent to a server in plain text\n",
        "   - Server can see and store the actual facial features\n",
        "   - Server can potentially misuse or leak the sensitive biometric data\n",
        "\n",
        "2. **Homomorphic Approach (Privacy-Preserving)**:\n",
        "   - Facial embeddings are encrypted before being sent to the server\n",
        "   - Server can perform computations on encrypted data without seeing the actual values\n",
        "   - Only the final result (match/no match) is decrypted by the client\n",
        "   - Server cannot access or misuse the sensitive biometric data\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "1. **Client Side**:\n",
        "   - Generates encryption keys\n",
        "   - Performs facial embedding extraction\n",
        "   - Encrypts the embeddings\n",
        "   - Decrypts final results\n",
        "\n",
        "2. **Server Side**:\n",
        "   - Receives encrypted embeddings\n",
        "   - Performs distance calculations on encrypted data\n",
        "   - Returns encrypted results\n",
        "   - Never sees actual facial features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7db053",
      "metadata": {
        "id": "ed7db053"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "We'll use the following libraries:\n",
        "- `tenseal`: For homomorphic encryption operations\n",
        "- `deepface`: For facial recognition and embedding extraction\n",
        "\n",
        "pip install tenseal; pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cefcf6ba",
      "metadata": {
        "id": "cefcf6ba"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "You have tensorflow 2.19.0 and this requires tf-keras package. Please run `pip install tf-keras` or downgrade your tensorflow.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\workspace\\SECURITY-project-MAADM-UPM\\.venv\\Lib\\site-packages\\retinaface\\commons\\package_utils.py:19\u001b[39m, in \u001b[36mvalidate_for_keras3\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf_keras\u001b[39;00m\n\u001b[32m     21\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtf_keras is already available - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_keras.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tf_keras'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtenseal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mts\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m norm\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\workspace\\SECURITY-project-MAADM-UPM\\.venv\\Lib\\site-packages\\deepface\\DeepFace.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m package_utils, folder_utils\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     modeling,\n\u001b[32m     22\u001b[39m     representation,\n\u001b[32m     23\u001b[39m     verification,\n\u001b[32m     24\u001b[39m     recognition,\n\u001b[32m     25\u001b[39m     demography,\n\u001b[32m     26\u001b[39m     detection,\n\u001b[32m     27\u001b[39m     streaming,\n\u001b[32m     28\u001b[39m     preprocessing,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     32\u001b[39m logger = Logger()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\workspace\\SECURITY-project-MAADM-UPM\\.venv\\Lib\\site-packages\\deepface\\modules\\modeling.py:16\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfacial_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     VGGFace,\n\u001b[32m      7\u001b[39m     OpenFace,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     GhostFaceNet,\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mface_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     FastMtCnn,\n\u001b[32m     18\u001b[39m     MediaPipe,\n\u001b[32m     19\u001b[39m     MtCnn,\n\u001b[32m     20\u001b[39m     OpenCv,\n\u001b[32m     21\u001b[39m     Dlib \u001b[38;5;28;01mas\u001b[39;00m DlibDetector,\n\u001b[32m     22\u001b[39m     RetinaFace,\n\u001b[32m     23\u001b[39m     Ssd,\n\u001b[32m     24\u001b[39m     Yolo,\n\u001b[32m     25\u001b[39m     YuNet,\n\u001b[32m     26\u001b[39m     CenterFace,\n\u001b[32m     27\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdemography\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Age, Gender, Race, Emotion\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspoofing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FasNet\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\workspace\\SECURITY-project-MAADM-UPM\\.venv\\Lib\\site-packages\\deepface\\models\\face_detection\\RetinaFace.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mretinaface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetinaFace \u001b[38;5;28;01mas\u001b[39;00m rf\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mDetector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Detector, FacialAreaRegion\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# pylint: disable=too-few-public-methods\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\workspace\\SECURITY-project-MAADM-UPM\\.venv\\Lib\\site-packages\\retinaface\\RetinaFace.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mretinaface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m package_utils\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# users should install tf_keras package if they are using tf 2.16 or later versions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mpackage_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_for_keras3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m logger = Logger(module=\u001b[33m\"\u001b[39m\u001b[33mretinaface/RetinaFace.py\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# pylint: disable=global-variable-undefined, no-name-in-module, unused-import, too-many-locals, redefined-outer-name, too-many-statements, too-many-arguments\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# configurations\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\workspace\\SECURITY-project-MAADM-UPM\\.venv\\Lib\\site-packages\\retinaface\\commons\\package_utils.py:24\u001b[39m, in \u001b[36mvalidate_for_keras3\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtf_keras is already available - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_keras.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# you may consider to install that package here\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     25\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou have tensorflow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and this requires \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtf-keras package. Please run `pip install tf-keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor downgrade your tensorflow.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: You have tensorflow 2.19.0 and this requires tf-keras package. Please run `pip install tf-keras` or downgrade your tensorflow."
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import tenseal as ts\n",
        "import numpy as np\n",
        "from deepface import DeepFace\n",
        "from numpy.linalg import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7cfa85",
      "metadata": {
        "id": "8c7cfa85"
      },
      "source": [
        "# Finding embeddings (Client Side)\n",
        "We are going to find vector representations of facial images. This will be done in the client side to ensure the raw facial data never leaves the user's device.\n",
        "\n",
        "The embeddings are 128-dimensional vectors that represent the unique features of each face. These embeddings are what we'll encrypt before sending to the server.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9af942",
      "metadata": {
        "id": "3f9af942"
      },
      "outputs": [],
      "source": [
        "img1_path = \"data/z1.jpg\"\n",
        "img2_path = \"data/th1.jpg\"\n",
        "img1_embedding = DeepFace.represent(img1_path, model_name='Facenet')\n",
        "img2_embedding = DeepFace.represent(img2_path, model_name='Facenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1d3a6d",
      "metadata": {
        "id": "6c1d3a6d"
      },
      "source": [
        "# Utility Functions\n",
        "Utility functions for handling encrypted data:\n",
        "- `write_data`: Saves encrypted data to files (simulating cloud storage)\n",
        "- `read_data`: Reads encrypted data from files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "44630098",
      "metadata": {
        "id": "44630098"
      },
      "outputs": [],
      "source": [
        "def write_data(file_name, file_content):\n",
        "    if type(file_content) == bytes:\n",
        "        #bytes to base64\n",
        "        file_content = base64.b64encode(file_content)\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(file_content)\n",
        "\n",
        "def read_data(file_name):\n",
        "    with open(file_name, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    #base64 to bytes\n",
        "    return base64.b64decode(file_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e70aa6a",
      "metadata": {
        "id": "8e70aa6a"
      },
      "source": [
        "# Initialization (Client Side)\n",
        "Here we set up the homomorphic encryption context with CKKS scheme, which allows us to perform computations on encrypted real numbers. The parameters are chosen to balance security and performance:\n",
        "\n",
        "- `poly_modulus_degree = 8192`: Determines the size of encrypted vectors\n",
        "- `coeff_mod_bit_sizes = [60, 40, 40, 60]`: Controls the precision of computations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "237b951e",
      "metadata": {
        "id": "237b951e"
      },
      "outputs": [],
      "source": [
        "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree = 8192, coeff_mod_bit_sizes = [60, 40, 40, 60])\n",
        "context.generate_galois_keys()\n",
        "context.global_scale = 2**40\n",
        "secret_context = context.serialize(save_secret_key = True)\n",
        "write_data(\"secret.txt\", file_content=secret_context)\n",
        "type(secret_context)\n",
        "context.make_context_public()\n",
        "public_context=context.serialize()\n",
        "write_data(file_name=\"public.txt\",file_content=public_context)\n",
        "del context, secret_context, public_context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69af1e96",
      "metadata": {
        "id": "69af1e96"
      },
      "source": [
        "# Encryption\n",
        "In this step, we encrypt the facial embeddings before they would be sent to the server. This is crucial for privacy because:\n",
        "1. The server never sees the actual facial features\n",
        "2. The encrypted data cannot be reverse-engineered to recover the original face\n",
        "3. Even if the server is compromised, the attacker cannot access the biometric data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4edce248",
      "metadata": {
        "id": "4edce248"
      },
      "outputs": [],
      "source": [
        "context = ts.context_from(read_data(\"secret.txt\"))\n",
        "enc_v1 = ts.ckks_vector(context, img1_embedding[0]['embedding'])\n",
        "enc_v2 = ts.ckks_vector(context, img2_embedding[0]['embedding'])\n",
        "enc_v1_proto = enc_v1.serialize()\n",
        "enc_v2_proto = enc_v2.serialize()\n",
        "write_data(\"enc_v1.txt\", enc_v1_proto)\n",
        "write_data(\"enc_v2.txt\", enc_v2_proto)\n",
        "del context, enc_v1, enc_v2, enc_v1_proto, enc_v2_proto"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ddbbe9f",
      "metadata": {
        "id": "7ddbbe9f"
      },
      "source": [
        "# Calculations (Server side)\n",
        "This section demonstrates the power of homomorphic encryption. The server can:\n",
        "1. Load the encrypted embeddings\n",
        "2. Compute the Euclidean distance between them\n",
        "3. All while never seeing the actual facial features\n",
        "\n",
        "The server only has access to the public key, so it cannot decrypt the data. This ensures the privacy of the biometric data even during computation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1da906b4",
      "metadata": {
        "id": "1da906b4"
      },
      "outputs": [],
      "source": [
        "context = ts.context_from(read_data(\"public.txt\"))\n",
        "enc_v1_proto = read_data(\"enc_v1.txt\")\n",
        "enc_v2_proto = read_data(\"enc_v2.txt\")\n",
        "enc_v1 = ts.lazy_ckks_vector_from(enc_v1_proto)\n",
        "enc_v1.link_context(context)\n",
        "\n",
        "enc_v2 = ts.lazy_ckks_vector_from(enc_v2_proto)\n",
        "enc_v2.link_context(context)\n",
        "euclidean_squared = enc_v1 - enc_v2\n",
        "euclidean_squared = euclidean_squared.dot(euclidean_squared)\n",
        "write_data(\"euclidean_squared.txt\", euclidean_squared.serialize())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2f4fdf88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f4fdf88",
        "outputId": "3cc5b470-77f7-40ef-bd44-bc1ae879ea33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception:  the current context of the tensor doesn't hold a secret_key, please provide one as argument\n"
          ]
        }
      ],
      "source": [
        "# we must not decrypt the homomorphic encrypted euclidean squared value in this stage\n",
        "# because we don't have the secret key. check this operation. it should throw an exception!\n",
        "\n",
        "try:\n",
        "    euclidean_squared.decrypt()\n",
        "except Exception as err:\n",
        "    print(\"Exception: \", str(err))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1bd4a0d1",
      "metadata": {
        "id": "1bd4a0d1"
      },
      "outputs": [],
      "source": [
        "del context, enc_v1_proto, enc_v2_proto, enc_v1, enc_v2, euclidean_squared"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6b89433",
      "metadata": {
        "id": "a6b89433"
      },
      "source": [
        "# Decryption (Client side)\n",
        "\n",
        "Only the client can decrypt the results because only they possess the secret key. This means:\n",
        "1. The server cannot see whether faces match or not\n",
        "2. The final result is only revealed to the authorized client\n",
        "3. The entire process maintains privacy while still providing accurate results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "86880fcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86880fcc",
        "outputId": "864a6dd9-5740-4c24-d984-f44b368b9281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "they are different persons\n"
          ]
        }
      ],
      "source": [
        "context = ts.context_from(read_data(\"secret.txt\"))\n",
        "euclidean_squared_proto = read_data(\"euclidean_squared.txt\")\n",
        "euclidean_squared = ts.lazy_ckks_vector_from(euclidean_squared_proto)\n",
        "euclidean_squared.link_context(context)\n",
        "euclidean_squared_plain = euclidean_squared.decrypt()[0]\n",
        "euclidean_squared_plain\n",
        "if euclidean_squared_plain < 100:\n",
        "    print(\"they are same person\")\n",
        "else:\n",
        "    print(\"they are different persons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18a58380",
      "metadata": {
        "id": "18a58380"
      },
      "source": [
        "# Validation\n",
        "This section compares the results of traditional (unencrypted) and homomorphic (encrypted) computations to verify that:\n",
        "1. The homomorphic encryption provides the same accuracy as traditional methods\n",
        "2. The small difference in results is due to the inherent approximation in homomorphic encryption\n",
        "3. The privacy benefits come without sacrificing accuracy\n",
        "\n",
        "The difference between traditional and homomorphic results should be negligible (< 0.00001), proving that we can achieve privacy without compromising the functionality of the facial recognition system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b929f080",
      "metadata": {
        "id": "b929f080"
      },
      "outputs": [],
      "source": [
        "img1_emb = np.array(img1_embedding[0][\"embedding\"])\n",
        "img2_emb = np.array(img2_embedding[0][\"embedding\"])\n",
        "distance = norm(img1_emb - img2_emb )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d8ddcac1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ddcac1",
        "outputId": "7b8e84c8-04e2-4f94-e8ee-d12e288103df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "euclidean squared - tradational:  276.97510330867624\n",
            "euclidean squared - homomorphic:  276.97514287660164\n"
          ]
        }
      ],
      "source": [
        "print(\"euclidean squared - tradational: \", distance*distance)\n",
        "print(\"euclidean squared - homomorphic: \", euclidean_squared_plain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7de6471a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7de6471a",
        "outputId": "febeafad-c143-4553-c484-d6a214da733f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.False_"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check the difference is acceptable\n",
        "abs(distance * distance - euclidean_squared_plain) < 0.00001"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
